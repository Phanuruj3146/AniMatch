{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvcMQzFckjXd",
        "outputId": "ed13ecce-7aae-4021-d5f6-7bf17d6f1013"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  2  955k    2 19883    0     0  20880      0  0:00:46 --:--:--  0:00:46 20907\n",
            "  9  955k    9 93323    0     0  45087      0  0:00:21  0:00:02  0:00:19 45127\n",
            " 15  955k   15  151k    0     0  51508      0  0:00:18  0:00:03  0:00:15 51541\n",
            " 22  955k   22  213k    0     0  55481      0  0:00:17  0:00:03  0:00:14 55497\n",
            " 30  955k   30  286k    0     0  59380      0  0:00:16  0:00:04  0:00:12 59385\n",
            " 40  955k   40  387k    0     0  64810      0  0:00:15  0:00:06  0:00:09 72904\n",
            " 48  955k   48  463k    0     0  67363      0  0:00:14  0:00:07  0:00:07 76611\n",
            " 56  955k   56  539k    0     0  69549      0  0:00:14  0:00:07  0:00:07 80567\n",
            " 64  955k   64  615k    0     0  69189      0  0:00:14  0:00:09  0:00:05 79644\n",
            " 72  955k   72  694k    0     0  71059      0  0:00:13  0:00:10  0:00:03 82464\n",
            " 82  955k   82  790k    0     0  73696      0  0:00:13  0:00:10  0:00:03 84915\n",
            " 91  955k   91  877k    0     0  73823      0  0:00:13  0:00:12  0:00:01 82735\n",
            "100  955k  100  955k    0     0  76400      0  0:00:12  0:00:12 --:--:-- 87609\n"
          ]
        }
      ],
      "source": [
        "# Data Citation:\n",
        "# F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on\n",
        "# Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>\n",
        "\n",
        "! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "68BdqtQikvVE"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OmO7jmrpkvZf"
      },
      "outputs": [],
      "source": [
        "# import the dataset\n",
        "import pandas as pd\n",
        "movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n",
        "ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-KRTGaskvdn",
        "outputId": "3f86c48c-56a2-4f93-bd07-1d2b76d3a448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dimensions of movies dataframe are: (9742, 3) \n",
            "The dimensions of ratings dataframe are: (100836, 4)\n"
          ]
        }
      ],
      "source": [
        "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ALPeuAiBk0mM",
        "outputId": "b451a704-6e60-4821-de8c-ba0957f0e2d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId                               title  \\\n",
              "0        1                    Toy Story (1995)   \n",
              "1        2                      Jumanji (1995)   \n",
              "2        3             Grumpier Old Men (1995)   \n",
              "3        4            Waiting to Exhale (1995)   \n",
              "4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                   Adventure|Children|Fantasy  \n",
              "2                               Comedy|Romance  \n",
              "3                         Comedy|Drama|Romance  \n",
              "4                                       Comedy  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a look at movies_df\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KzPoqkWbk0oh",
        "outputId": "15cd8f84-0bed-4003-efdb-c46a3e1676b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a look at ratings_df\n",
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TUaWt96k0q7",
        "outputId": "58a11c19-b6df-4879-8f4d-5665a52c4d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique users: 610\n",
            "Number of unique movies: 9724\n",
            "The full rating matrix will have: 5931640 elements.\n",
            "----------\n",
            "Number of ratings: 100836\n",
            "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
            "We have an incredibly sparse matrix to work with here.\n",
            "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
            "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
            "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
          ]
        }
      ],
      "source": [
        "# Movie ID to movie name mapping\n",
        "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
        "n_users = len(ratings_df.userId.unique())\n",
        "n_items = len(ratings_df.movieId.unique())\n",
        "print(\"Number of unique users:\", n_users)\n",
        "print(\"Number of unique movies:\", n_items)\n",
        "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
        "print('----------')\n",
        "print(\"Number of ratings:\", len(ratings_df))\n",
        "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
        "print(\"We have an incredibly sparse matrix to work with here.\")\n",
        "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
        "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
        "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YnkTvMsCk0tY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "class MatrixFactorization(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=20):\n",
        "        super().__init__()\n",
        "        # create user embeddings\n",
        "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
        "        # create item embeddings\n",
        "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
        "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
        "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # matrix multiplication\n",
        "        users, items = data[:,0], data[:,1]\n",
        "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
        "    # def forward(self, user, item):\n",
        "    # \t# matrix multiplication\n",
        "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
        "\n",
        "    # def predict(self, user, item):\n",
        "    #     return self.forward(user, item)\n",
        "\n",
        "    def predict(self, data):\n",
        "        users, items = data[:, 0], data[:, 1]\n",
        "        return self.forward(data)\n",
        "\n",
        "    def recommend_movies(self, user_id, n=10):\n",
        "        \"\"\"\n",
        "        Recommends top-N movies for a given user.\n",
        "\n",
        "        Parameters:\n",
        "            user_id (int): User ID for whom recommendations are made.\n",
        "            n (int): Number of recommendations to return.\n",
        "\n",
        "        Returns:\n",
        "            list: List of movie IDs recommended for the user.\n",
        "        \"\"\"\n",
        "        # Convert user ID to continuous index\n",
        "        user_idx = train_set.userid2idx[user_id]\n",
        "        print(f\"user index: {user_idx}\" )\n",
        "\n",
        "        # Get all movie indices\n",
        "        all_movie_indices = torch.arange(len(train_set.idx2movieid))\n",
        "        print(f\"all movie indices: {all_movie_indices}\")\n",
        "\n",
        "        # Create user-movie pairs for predictions\n",
        "        user_movie_indices = torch.cartesian_prod(torch.tensor([user_idx]), all_movie_indices)\n",
        "        print(f\"Create user-movie pairs for predictions: {user_movie_indices}\")\n",
        "\n",
        "        # Combine user and movie indices into a single tensor\n",
        "        user_movie_tensor = torch.tensor(list(zip(user_movie_indices[:, 0], user_movie_indices[:, 1])))\n",
        "        print(f\" Combine user and movie indices into a single tensor: {user_movie_tensor}\")\n",
        "\n",
        "        # Move the input tensor to GPU if available\n",
        "        if cuda:\n",
        "            user_movie_tensor = user_movie_tensor.cuda()\n",
        "\n",
        "        # Make predictions for all user-movie pairs\n",
        "        predictions = self.predict(user_movie_tensor)\n",
        "\n",
        "        # Sort movie indices based on predicted ratings in descending order\n",
        "        sorted_indices = torch.argsort(predictions, descending=True)\n",
        "\n",
        "        # Extract top-N movie indices\n",
        "        top_n_indices = sorted_indices[:n]\n",
        "\n",
        "        # Convert movie indices back to movie IDs\n",
        "        top_n_movie_ids = [train_set.idx2movieid[idx.item()] for idx in top_n_indices]\n",
        "\n",
        "        return top_n_movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LTlGvz7sk0v2"
      },
      "outputs": [],
      "source": [
        "# Creating the dataloader (necessary for PyTorch)\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
        "\n",
        "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
        "class Loader(Dataset):\n",
        "    def __init__(self):\n",
        "        self.ratings = ratings_df.copy()\n",
        "\n",
        "        # Extract all user IDs and movie IDs\n",
        "        users = ratings_df.userId.unique()\n",
        "        movies = ratings_df.movieId.unique()\n",
        "\n",
        "        #--- Producing new continuous IDs for users and movies ---\n",
        "\n",
        "        # Unique values : index\n",
        "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
        "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
        "\n",
        "        # Obtained continuous ID for users and movies\n",
        "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
        "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
        "\n",
        "        # return the id from the indexed values as noted in the lambda function down below.\n",
        "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
        "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
        "\n",
        "\n",
        "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
        "        self.y = self.ratings['rating'].values\n",
        "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6MK3Ymmk0yi",
        "outputId": "90591eeb-7caa-4477-f5d4-29c86e305cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is running on GPU: False\n",
            "MatrixFactorization(\n",
            "  (user_factors): Embedding(610, 8)\n",
            "  (item_factors): Embedding(9724, 8)\n",
            ")\n",
            "user_factors.weight tensor([[0.0056, 0.0132, 0.0414,  ..., 0.0498, 0.0086, 0.0200],\n",
            "        [0.0141, 0.0377, 0.0091,  ..., 0.0236, 0.0154, 0.0446],\n",
            "        [0.0395, 0.0002, 0.0163,  ..., 0.0276, 0.0180, 0.0232],\n",
            "        ...,\n",
            "        [0.0258, 0.0215, 0.0195,  ..., 0.0057, 0.0251, 0.0433],\n",
            "        [0.0494, 0.0229, 0.0222,  ..., 0.0435, 0.0377, 0.0020],\n",
            "        [0.0034, 0.0370, 0.0248,  ..., 0.0351, 0.0348, 0.0232]])\n",
            "item_factors.weight tensor([[0.0278, 0.0273, 0.0250,  ..., 0.0408, 0.0346, 0.0437],\n",
            "        [0.0301, 0.0046, 0.0133,  ..., 0.0239, 0.0320, 0.0325],\n",
            "        [0.0132, 0.0262, 0.0387,  ..., 0.0116, 0.0418, 0.0119],\n",
            "        ...,\n",
            "        [0.0081, 0.0041, 0.0302,  ..., 0.0117, 0.0344, 0.0145],\n",
            "        [0.0395, 0.0341, 0.0351,  ..., 0.0043, 0.0168, 0.0036],\n",
            "        [0.0339, 0.0274, 0.0468,  ..., 0.0215, 0.0162, 0.0041]])\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 128\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Is running on GPU:\", cuda)\n",
        "\n",
        "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
        "print(model)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "# GPU enable if you have a GPU...\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# ADAM optimizier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train data\n",
        "train_set = Loader()\n",
        "train_loader = DataLoader(train_set, 128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4751ad975aa849c898b6d2a94765a006",
            "3054048cc7fb4dd1b535965bbf8ad8af",
            "4581b1f0951a4f39b65ac0f604ad01eb",
            "3c26f49828264104b685448f4ecd3d37",
            "af25728def0b4a3c85e43356a2bbdad8",
            "7c539cd542574c01a1ff18727bd9b281",
            "ad4e953d908c4008ad06e836341dd4b9",
            "c1f907b3daac429c987dc81269e3c955",
            "6fe79b8097b141eb821e1985442d17b2",
            "3653f5d0d09345cab18645aa4525b0dc",
            "53e32a6c66eb41349e43a534b3c3b824"
          ]
        },
        "id": "8fIDIdStk000",
        "outputId": "a695dd9e-baaf-4993-db78-2e7c5a9ae049"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Roze\\AppData\\Local\\Temp\\ipykernel_8456\\59576823.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for it in tqdm(range(num_epochs)):\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\__init__.py:28\u001b[0m, in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m _tqdm_notebook\n\u001b[0;32m     25\u001b[0m warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function will be removed in tqdm==5.0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m      TqdmDeprecationWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tqdm_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
            "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
          ]
        }
      ],
      "source": [
        "for it in tqdm(range(num_epochs)):\n",
        "    losses = []\n",
        "    for x, y in train_loader:\n",
        "         if cuda:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs_GVbSYmhib",
        "outputId": "5b57b096-cdab-4c6e-dcb0-bcc53e23b4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_factors.weight tensor([[ 1.1034,  1.4892,  0.7528,  ...,  1.3036,  1.0512,  1.5724],\n",
            "        [ 1.5081, -0.0813,  0.2775,  ...,  1.9494,  0.9154,  1.0569],\n",
            "        [ 0.2833,  0.0605,  0.9062,  ...,  2.8402, -1.6074,  1.3509],\n",
            "        ...,\n",
            "        [ 2.7284,  0.2840,  0.0313,  ..., -0.0923,  0.6011,  1.0638],\n",
            "        [ 0.8062,  0.7465,  0.9239,  ...,  1.4485,  1.0231,  1.1420],\n",
            "        [ 1.1826,  1.3374,  1.4770,  ...,  0.9632,  0.8720,  1.3309]],\n",
            "       device='cuda:0')\n",
            "item_factors.weight tensor([[0.4605, 0.5332, 0.8383,  ..., 0.3537, 0.4206, 0.3439],\n",
            "        [0.2664, 0.2682, 0.4361,  ..., 1.0213, 0.2412, 0.4369],\n",
            "        [0.6715, 0.5397, 0.6165,  ..., 0.6072, 0.4597, 0.0573],\n",
            "        ...,\n",
            "        [0.3439, 0.3727, 0.3536,  ..., 0.3634, 0.3803, 0.3565],\n",
            "        [0.4024, 0.3834, 0.3954,  ..., 0.4149, 0.3882, 0.3858],\n",
            "        [0.4275, 0.4095, 0.4092,  ..., 0.3881, 0.4205, 0.4229]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# By training the model, we will have tuned latent factors for movies and users.\n",
        "c = 0\n",
        "uw = 0\n",
        "iw = 0\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "        if c == 0:\n",
        "          uw = param.data\n",
        "          c +=1\n",
        "        else:\n",
        "          iw = param.data\n",
        "        #print('param_data', param_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJgie01_p8k5"
      },
      "outputs": [],
      "source": [
        "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-_tHZ_E_rub",
        "outputId": "33c80168-f539-4a7c-b773-18edbad4ca2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9724"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trained_movie_embeddings) # unique movie factor weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9s4iqXy75q",
        "outputId": "a4dee956-b5dc-4e6b-cf1e-cea4f17e1a14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "# Fit the clusters based on the movie weights\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MDzp-9u-m5n",
        "outputId": "bbc8128e-c205-46ef-f0ae-e1add21d5ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster #0\n",
            "\t Ace Ventura: Pet Detective (1994)\n",
            "\t Mask, The (1994)\n",
            "\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
            "\t Clueless (1995)\n",
            "\t Happy Gilmore (1996)\n",
            "\t While You Were Sleeping (1995)\n",
            "\t Ace Ventura: When Nature Calls (1995)\n",
            "\t Mummy, The (1999)\n",
            "\t Jerry Maguire (1996)\n",
            "Cluster #1\n",
            "\t Forrest Gump (1994)\n",
            "\t Shawshank Redemption, The (1994)\n",
            "\t Silence of the Lambs, The (1991)\n",
            "\t Matrix, The (1999)\n",
            "\t Braveheart (1995)\n",
            "\t Toy Story (1995)\n",
            "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
            "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
            "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
            "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
            "Cluster #2\n",
            "\t Pulp Fiction (1994)\n",
            "\t Fight Club (1999)\n",
            "\t Usual Suspects, The (1995)\n",
            "\t American Beauty (1999)\n",
            "\t Godfather, The (1972)\n",
            "\t Fargo (1996)\n",
            "\t Memento (2000)\n",
            "\t Alien (1979)\n",
            "\t Inception (2010)\n",
            "\t Monty Python and the Holy Grail (1975)\n",
            "Cluster #3\n",
            "\t Jurassic Park (1993)\n",
            "\t Terminator 2: Judgment Day (1991)\n",
            "\t Batman (1989)\n",
            "\t Saving Private Ryan (1998)\n",
            "\t Aladdin (1992)\n",
            "\t Sixth Sense, The (1999)\n",
            "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
            "\t Lion King, The (1994)\n",
            "\t Speed (1994)\n",
            "\t Gladiator (2000)\n",
            "Cluster #4\n",
            "\t Independence Day (a.k.a. ID4) (1996)\n",
            "\t True Lies (1994)\n",
            "\t Mission: Impossible (1996)\n",
            "\t Mrs. Doubtfire (1993)\n",
            "\t Stargate (1994)\n",
            "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
            "\t Pretty Woman (1990)\n",
            "\t GoldenEye (1995)\n",
            "\t Twister (1996)\n",
            "\t Home Alone (1990)\n",
            "Cluster #5\n",
            "\t Titanic (1997)\n",
            "\t Batman Forever (1995)\n",
            "\t Net, The (1995)\n",
            "\t American Pie (1999)\n",
            "\t Avatar (2009)\n",
            "\t Star Wars: Episode II - Attack of the Clones (2002)\n",
            "\t Matrix Revolutions, The (2003)\n",
            "\t Scream (1996)\n",
            "\t Patriot, The (2000)\n",
            "\t Desperado (1995)\n",
            "Cluster #6\n",
            "\t Charlie's Angels: Full Throttle (2003)\n",
            "\t Fantastic Four: Rise of the Silver Surfer (2007)\n",
            "\t Honey, I Blew Up the Kid (1992)\n",
            "\t Speed 2: Cruise Control (1997)\n",
            "\t Superman IV: The Quest for Peace (1987)\n",
            "\t Nutty Professor II: The Klumps (2000)\n",
            "\t Karate Kid, Part III, The (1989)\n",
            "\t Bewitched (2005)\n",
            "\t Dungeons & Dragons (2000)\n",
            "\t Dukes of Hazzard, The (2005)\n",
            "Cluster #7\n",
            "\t Seven (a.k.a. Se7en) (1995)\n",
            "\t Babe (1995)\n",
            "\t Willy Wonka & the Chocolate Factory (1971)\n",
            "\t Interview with the Vampire: The Vampire Chronicles (1994)\n",
            "\t Big Lebowski, The (1998)\n",
            "\t O Brother, Where Art Thou? (2000)\n",
            "\t Natural Born Killers (1994)\n",
            "\t Mars Attacks! (1996)\n",
            "\t Casino (1995)\n",
            "\t Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan (2006)\n",
            "Cluster #8\n",
            "\t Star Wars: Episode IV - A New Hope (1977)\n",
            "\t Schindler's List (1993)\n",
            "\t Apollo 13 (1995)\n",
            "\t Fugitive, The (1993)\n",
            "\t Back to the Future (1985)\n",
            "\t Shrek (2001)\n",
            "\t Beauty and the Beast (1991)\n",
            "\t Princess Bride, The (1987)\n",
            "\t E.T. the Extra-Terrestrial (1982)\n",
            "\t Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)\n",
            "Cluster #9\n",
            "\t Waterworld (1995)\n",
            "\t Back to the Future Part III (1990)\n",
            "\t Back to the Future Part II (1989)\n",
            "\t Robin Hood: Men in Tights (1993)\n",
            "\t Juno (2007)\n",
            "\t Casper (1995)\n",
            "\t Predator (1987)\n",
            "\t Beverly Hills Cop III (1994)\n",
            "\t Congo (1995)\n",
            "\t Pirates of the Caribbean: At World's End (2007)\n"
          ]
        }
      ],
      "source": [
        "'''It can be seen here that the movies that are in the same cluster tend to have\n",
        "similar genres. Also note that the algorithm is unfamiliar with the movie name\n",
        "and only obtained the relationships by looking at the numbers representing how\n",
        "users have responded to the movie selections.'''\n",
        "for cluster in range(10):\n",
        "  print(\"Cluster #{}\".format(cluster))\n",
        "  movs = []\n",
        "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
        "    movid = train_set.idx2movieid[movidx]\n",
        "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
        "    movs.append((movie_names[movid], rat_count))\n",
        "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
        "    print(\"\\t\", mov[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29wtWMZnwavx",
        "outputId": "1d99e30b-b975-453f-8775-1ce558c04700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user index: 2\n",
            "all movie indices: tensor([   0,    1,    2,  ..., 9721, 9722, 9723])\n",
            "Create user-movie pairs for predictions: tensor([[   2,    0],\n",
            "        [   2,    1],\n",
            "        [   2,    2],\n",
            "        ...,\n",
            "        [   2, 9721],\n",
            "        [   2, 9722],\n",
            "        [   2, 9723]])\n",
            " Combine user and movie indices into a single tensor: tensor([[   2,    0],\n",
            "        [   2,    1],\n",
            "        [   2,    2],\n",
            "        ...,\n",
            "        [   2, 9721],\n",
            "        [   2, 9722],\n",
            "        [   2, 9723]])\n",
            "Recommended Movies for User 3: [4509, 6322, 4564, 6436, 5265, 407, 354, 7381, 3113, 4649]\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'user_id' is the user for whom recommendations are requested\n",
        "user_id = 3\n",
        "\n",
        "# Make recommendations for the user\n",
        "recommended_movies = model.recommend_movies(user_id, n=10)\n",
        "\n",
        "# Print the recommended movies\n",
        "print(\"Recommended Movies for User {}: {}\".format(user_id, recommended_movies))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3054048cc7fb4dd1b535965bbf8ad8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c539cd542574c01a1ff18727bd9b281",
            "placeholder": "​",
            "style": "IPY_MODEL_ad4e953d908c4008ad06e836341dd4b9",
            "value": "100%"
          }
        },
        "3653f5d0d09345cab18645aa4525b0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c26f49828264104b685448f4ecd3d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3653f5d0d09345cab18645aa4525b0dc",
            "placeholder": "​",
            "style": "IPY_MODEL_53e32a6c66eb41349e43a534b3c3b824",
            "value": " 128/128 [03:40&lt;00:00,  1.79s/it]"
          }
        },
        "4581b1f0951a4f39b65ac0f604ad01eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f907b3daac429c987dc81269e3c955",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fe79b8097b141eb821e1985442d17b2",
            "value": 128
          }
        },
        "4751ad975aa849c898b6d2a94765a006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3054048cc7fb4dd1b535965bbf8ad8af",
              "IPY_MODEL_4581b1f0951a4f39b65ac0f604ad01eb",
              "IPY_MODEL_3c26f49828264104b685448f4ecd3d37"
            ],
            "layout": "IPY_MODEL_af25728def0b4a3c85e43356a2bbdad8"
          }
        },
        "53e32a6c66eb41349e43a534b3c3b824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fe79b8097b141eb821e1985442d17b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c539cd542574c01a1ff18727bd9b281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4e953d908c4008ad06e836341dd4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af25728def0b4a3c85e43356a2bbdad8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f907b3daac429c987dc81269e3c955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
